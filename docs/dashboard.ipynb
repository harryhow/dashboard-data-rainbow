{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d90e33ab",
   "metadata": {},
   "source": [
    "# Dashboard Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a864121f-11a2-463e-8864-9224d873f5ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media present in 'data', skip unzip.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c033238cca2b4b089804ce985a881ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Map(center=[23.565, 119.579], close_popup_on_click=False, controls=(ZoomControl(options=['posit…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# === ================================================================================\n",
    "# === Dashboard v1.0 — — dashboard for data rainbow project\n",
    "# === ================================================================================\n",
    "\n",
    "import os, os.path as osp, json, re, zipfile\n",
    "from urllib.parse import urlparse, quote as _urlquote\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as W\n",
    "from IPython.display import display\n",
    "\n",
    "import leafmap  # (ipyleaflet backend)\n",
    "from ipyleaflet import (\n",
    "    Marker, MarkerCluster, Popup, AwesomeIcon, WidgetControl,\n",
    "    FullScreenControl, ZoomControl\n",
    ")\n",
    "\n",
    "class DataRainbowDashboard:\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    # Config — file names & folders used by the dashboard\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    MEDIA_CSV  = \"media.csv\"    # Required: metadata table\n",
    "    LOCS_CSV   = \"location.csv\" # Optional: used when media.csv has location_tag\n",
    "    MEDIA_DIR  = \"data\"         # All media files live in ./data\n",
    "    SAMPLE_ZIP = \"sample.zip\"   # Optional: when present, auto-unzips into ./data at first run\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    # Colors & Icons — visual mapping for markers\n",
    "    # ----------------------------------------------------------------------------------------\n",
    "    PALETTE = [\"red\",\"darkred\",\"blue\",\"cadetblue\",\"green\",\"darkgreen\",\"orange\",\n",
    "               \"purple\",\"darkpurple\",\"pink\",\"gray\",\"black\",\"lightblue\"]\n",
    "    FA_BY_TYPE = {\"audio\":\"music\", \"video\":\"video-camera\", \"image\":\"image\"}\n",
    "\n",
    "    _DATE8 = re.compile(r\"^(\\d{4})(\\d{2})(\\d{2})(.*)$\")\n",
    "\n",
    "    def __init__(self):\n",
    "        # State (matches procedural version behavior)\n",
    "        self.DATA = pd.DataFrame()\n",
    "        self.media = pd.DataFrame()\n",
    "        self.DATA_LAYERS = []\n",
    "        self.DYNAMIC = {\"legend\": None, \"notice\": None}\n",
    "\n",
    "        self.FIRST_RENDER = True\n",
    "        self.LAST_FILTER_SIG = None\n",
    "        self.LAST_TYPE_SEL = None\n",
    "        self.LAST_EXTENT = None\n",
    "\n",
    "        self.w = {}  # widgets\n",
    "\n",
    "        # Startup sequence\n",
    "        self._ensure_unzipped()\n",
    "        self._load_data()\n",
    "        self._build_widgets()\n",
    "        self._init_map()\n",
    "        self._layout_panel()\n",
    "        self._wire_events()\n",
    "        self.render()\n",
    "\n",
    "    # ===================================== Utilities ============================================\n",
    "    \n",
    "    # Ensure working directory is the repo root so relative paths (media.csv, etc.) work\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "\n",
    "    def set_repo_cwd():\n",
    "        here = Path.cwd()\n",
    "        for p in [here, *here.parents]:\n",
    "            if (p / \"media.csv\").exists() or (p / \"location.csv\").exists():\n",
    "                os.chdir(p)\n",
    "                print(f\"Working directory set to repo root: {p}\")\n",
    "                return p\n",
    "        print(f\"Repo root not found; staying in: {here}\")\n",
    "        return here\n",
    "\n",
    "    REPO_ROOT = set_repo_cwd()\n",
    "    \n",
    "    @staticmethod\n",
    "    def infer_mime(url: str, fallback=\"audio/wav\"):\n",
    "        ext = osp.splitext(urlparse(str(url)).path)[1].lower()\n",
    "        return {\n",
    "            \".wav\":\"audio/wav\",\".mp3\":\"audio/mpeg\",\".m4a\":\"audio/mp4\",\".ogg\":\"audio/ogg\",\n",
    "            \".flac\":\"audio/flac\",\".aac\":\"audio/aac\",\n",
    "            \".mp4\":\"video/mp4\",\".webm\":\"video/webm\",\".mov\":\"video/quicktime\",\".m4v\":\"video/x-m4v\",\n",
    "            \".jpg\":\"image/jpeg\",\".jpeg\":\"image/jpeg\",\".png\":\"image/png\",\n",
    "            \".gif\":\"image/gif\",\".webp\":\"image/webp\"\n",
    "        }.get(ext, fallback)\n",
    "\n",
    "    @staticmethod\n",
    "    def first_text(*vals):\n",
    "        for v in vals:\n",
    "            if isinstance(v, str):\n",
    "                s = v.strip()\n",
    "                if s and s.lower() not in (\"nan\",\"na\",\"none\",\"null\"):\n",
    "                    return s\n",
    "        return None\n",
    "\n",
    "    def _parse_date_any(self, val):\n",
    "        if val is None or (isinstance(val, float) and np.isnan(val)): return pd.NaT\n",
    "        s = str(val).strip()\n",
    "        if not s or s.lower() in (\"nan\",\"na\",\"none\",\"null\"): return pd.NaT\n",
    "        ts = pd.to_datetime(s, errors=\"coerce\")\n",
    "        if pd.isna(ts):\n",
    "            m = self._DATE8.match(s)\n",
    "            if m:\n",
    "                y, mo, d, rest = m.groups()\n",
    "                ts = pd.to_datetime(f\"{y}-{mo}-{d}{rest}\".strip(), errors=\"coerce\")\n",
    "        return ts\n",
    "\n",
    "    @staticmethod\n",
    "    def coalesce_device_col(df_):\n",
    "        if \"device\" in df_.columns and \"device_meta\" in df_.columns:\n",
    "            s = df_[\"device\"].astype(str)\n",
    "            s = s.where(s.str.strip().ne(\"\"), df_[\"device_meta\"].astype(str))\n",
    "        elif \"device\" in df_.columns:\n",
    "            s = df_[\"device\"].astype(str)\n",
    "        elif \"device_meta\" in df_.columns:\n",
    "            s = df_[\"device_meta\"].astype(str)\n",
    "        else:\n",
    "            s = pd.Series([\"unknown\"]*len(df_))\n",
    "        return s.replace({\"nan\": np.nan}).fillna(\"unknown\").str.strip().replace({\"\": \"unknown\"})\n",
    "\n",
    "    import os, os.path as osp\n",
    "    from urllib.parse import quote as _urlquote\n",
    "\n",
    "    def _files_prefix(self) -> str:\n",
    "        \"\"\"\n",
    "        Correct Jupyter 'files' handler prefix:\n",
    "        - Binder/JupyterHub: '/user/<id>/files/'\n",
    "        - Local classic: '/files/'\n",
    "        \"\"\"\n",
    "        base = (\n",
    "            os.environ.get(\"JUPYTERHUB_SERVICE_PREFIX\")  # Binder / JupyterHub\n",
    "            or os.environ.get(\"NB_PREFIX\")               # sometimes set by Jupyter\n",
    "            or \"\"\n",
    "        )\n",
    "        base = (base or \"\").rstrip(\"/\")\n",
    "        return f\"{base}/files/\" if base else \"/files/\"\n",
    "\n",
    "    def _local_media_url(self, row) -> str:\n",
    "        \"\"\"\n",
    "        Resolve a local media URL for a given row (Series).\n",
    "        Returns a '/.../files/...' URL or '' if the file isn't present.\n",
    "        \"\"\"\n",
    "        fname = row.get(\"file_name\") or row.get(\"filename\")\n",
    "        if isinstance(fname, str) and fname.strip():\n",
    "            path = osp.join(self.MEDIA_DIR, fname)\n",
    "            if osp.exists(path):\n",
    "                rel = osp.relpath(path, start=\".\").replace(\"\\\\\", \"/\")\n",
    "                return self._files_prefix() + _urlquote(rel)\n",
    "        return \"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _guess_type_from_ext_or_field(row):\n",
    "        for k in (\"type\", \"media_type\", \"data_type\"):\n",
    "            v = str(row.get(k) or \"\").strip().lower()\n",
    "            if v in (\"audio\",\"video\",\"image\"):\n",
    "                return v\n",
    "        ext = str(row.get(\"extension\") or \"\").strip().lstrip(\".\").lower()\n",
    "        if not ext:\n",
    "            val = row.get(\"file_name\") or row.get(\"filename\") or \"\"\n",
    "            ext = osp.splitext(str(val))[1].lstrip(\".\").lower()\n",
    "        if ext in {\"wav\",\"mp3\",\"m4a\",\"ogg\",\"flac\",\"aac\"}: return \"audio\"\n",
    "        if ext in {\"mp4\",\"mov\",\"m4v\",\"webm\"}: return \"video\"\n",
    "        if ext in {\"jpg\",\"jpeg\",\"png\",\"gif\",\"webp\"}: return \"image\"\n",
    "        return \"audio\"\n",
    "\n",
    "    def _format_time_title(self, row):\n",
    "        v = row.get(\"date_norm\", None)\n",
    "        if v is not None and not (isinstance(v, float) and np.isnan(v)):\n",
    "            ts = pd.to_datetime(v, errors=\"coerce\")\n",
    "            if pd.notna(ts):\n",
    "                if ts.hour + ts.minute + ts.second > 0:\n",
    "                    return ts.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                return ts.strftime(\"%Y-%m-%d\")\n",
    "        dt_str = row.get(\"datetime\")\n",
    "        if isinstance(dt_str, str) and dt_str.strip(): return dt_str.strip()\n",
    "        donly = row.get(\"date_only\")\n",
    "        if pd.notna(donly): return str(donly)\n",
    "        return (row.get(\"display_name\") or \"Media\")\n",
    "\n",
    "    def _format_time_only(self, row):\n",
    "        v = row.get(\"date_norm\", None)\n",
    "        ts = pd.to_datetime(v, errors=\"coerce\")\n",
    "        if pd.notna(ts) and (ts.hour + ts.minute + ts.second > 0):\n",
    "            return ts.strftime(\"%H:%M:%S\")\n",
    "        t = row.get(\"time\")\n",
    "        if isinstance(t, str) and t.strip(): return t.strip()\n",
    "        return \"\"\n",
    "\n",
    "    # ================================= Files / Loading / Normalization ===========================\n",
    "    def _ensure_unzipped(self):\n",
    "        os.makedirs(self.MEDIA_DIR, exist_ok=True)\n",
    "        has_media = any(osp.isfile(osp.join(self.MEDIA_DIR, f)) for f in os.listdir(self.MEDIA_DIR))\n",
    "        if has_media:\n",
    "            print(f\"Media present in '{self.MEDIA_DIR}', skip unzip.\")\n",
    "            return\n",
    "        if not osp.exists(self.SAMPLE_ZIP):\n",
    "            print(\"sample.zip not found in root.\")\n",
    "            return\n",
    "        try:\n",
    "            with zipfile.ZipFile(self.SAMPLE_ZIP, \"r\") as zf:\n",
    "                zf.extractall(self.MEDIA_DIR)\n",
    "            print(f\"Unzipped '{self.SAMPLE_ZIP}' → '{self.MEDIA_DIR}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unzip failed: {e}\")\n",
    "\n",
    "    def _load_data(self):\n",
    "        if not osp.exists(self.MEDIA_CSV):\n",
    "            raise FileNotFoundError(f\"Missing {self.MEDIA_CSV}\")\n",
    "\n",
    "        media = pd.read_csv(self.MEDIA_CSV).copy()\n",
    "        media.columns = [c.strip().lower() for c in media.columns]\n",
    "\n",
    "        media[\"display_name\"] = media.apply(\n",
    "            lambda r: self.first_text(r.get(\"display_name\"), r.get(\"title\"), r.get(\"file_name\"),\n",
    "                                      r.get(\"name\"), r.get(\"stem\")) or \"Media\",\n",
    "            axis=1\n",
    "        )\n",
    "        media[\"type\"] = media.apply(self._guess_type_from_ext_or_field, axis=1)\n",
    "        media[\"device_display\"] = self.coalesce_device_col(media)\n",
    "\n",
    "        if \"date\" in media.columns:\n",
    "            d1 = media[\"date\"].apply(self._parse_date_any)\n",
    "        else:\n",
    "            d1 = pd.Series([pd.NaT]*len(media))\n",
    "        d2 = media[\"datetime\"].apply(self._parse_date_any) if \"datetime\" in media.columns else pd.Series([pd.NaT]*len(media))\n",
    "        if \"time\" in media.columns and \"date\" in media.columns:\n",
    "            dt_from_pair = pd.to_datetime(\n",
    "                media[\"date\"].astype(str).str.strip() + \" \" + media[\"time\"].astype(str).str.strip(),\n",
    "                errors=\"coerce\"\n",
    "            )\n",
    "            d2 = d2.fillna(dt_from_pair)\n",
    "        media[\"date_norm\"] = d1.fillna(d2)\n",
    "        media[\"date_only\"] = media[\"date_norm\"].dt.date\n",
    "\n",
    "        media[\"url\"] = media.apply(self._local_media_url, axis=1)\n",
    "\n",
    "        def _has_local_sample(r):\n",
    "            fname = r.get(\"file_name\") or r.get(\"filename\")\n",
    "            if isinstance(fname, str) and fname.strip():\n",
    "                p = osp.join(self.MEDIA_DIR, fname)\n",
    "                if osp.exists(p):\n",
    "                    return True\n",
    "            return False\n",
    "        media[\"has_media_local\"] = media.apply(_has_local_sample, axis=1)\n",
    "\n",
    "        # Coordinates: join via location_tag OR direct lat/lon\n",
    "        if \"location_tag\" in media.columns:\n",
    "            if not osp.exists(self.LOCS_CSV):\n",
    "                raise FileNotFoundError(\n",
    "                    f\"media.csv includes 'location_tag' but {self.LOCS_CSV} is missing. \"\n",
    "                    \"Either provide location.csv or drop 'location_tag' and add lat/lon directly in media.csv.\"\n",
    "                )\n",
    "            locs = pd.read_csv(self.LOCS_CSV).copy()\n",
    "            locs.columns = [c.strip().lower() for c in locs.columns]\n",
    "            for req_col in [\"location\", \"longitude\", \"latitude\"]:\n",
    "                if req_col not in locs.columns:\n",
    "                    raise ValueError(\"location.csv must have columns: location, longitude, latitude\")\n",
    "            locs2 = locs.rename(columns={\"longitude\":\"lon\",\"latitude\":\"lat\"})\n",
    "            for c in [\"lat\",\"lon\"]: locs2[c] = pd.to_numeric(locs2[c], errors=\"coerce\")\n",
    "            DATA = media.merge(\n",
    "                locs2[[\"location\",\"lat\",\"lon\"]],\n",
    "                left_on=\"location_tag\", right_on=\"location\", how=\"left\"\n",
    "            )\n",
    "        else:\n",
    "            cand_lat = next((c for c in [\"lat\",\"latitude\"] if c in media.columns), None)\n",
    "            cand_lon = next((c for c in [\"lon\",\"longitude\"] if c in media.columns), None)\n",
    "            if cand_lat and cand_lon:\n",
    "                DATA = media.copy()\n",
    "                DATA[\"lat\"] = pd.to_numeric(DATA[cand_lat], errors=\"coerce\")\n",
    "                DATA[\"lon\"] = pd.to_numeric(DATA[cand_lon], errors=\"coerce\")\n",
    "                if \"location\" not in DATA.columns and \"location_tag\" in DATA.columns:\n",
    "                    DATA[\"location\"] = DATA[\"location_tag\"]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"No 'location_tag' column and no direct coordinates found. \"\n",
    "                    \"Provide either 'location_tag' (and a location.csv) OR lat/lon (or latitude/longitude) in media.csv.\"\n",
    "                )\n",
    "\n",
    "        DATA[\"lat\"] = pd.to_numeric(DATA[\"lat\"], errors=\"coerce\")\n",
    "        DATA[\"lon\"] = pd.to_numeric(DATA[\"lon\"], errors=\"coerce\")\n",
    "\n",
    "        dedup_keys = [k for k in [\"file_name\",\"date_only\",\"lat\",\"lon\",\"type\"] if k in DATA.columns]\n",
    "        if dedup_keys:\n",
    "            DATA = DATA.sort_values(by=[\"date_norm\", \"file_name\"], na_position=\"last\").drop_duplicates(\n",
    "                subset=dedup_keys, keep=\"first\"\n",
    "            )\n",
    "\n",
    "        self.media = media\n",
    "        self.DATA  = DATA\n",
    "\n",
    "    # ================================= Widgets / Map / Layout ===================================\n",
    "    def _uniq(self, series):\n",
    "        if series is None: return []\n",
    "        return sorted(pd.Series(series).dropna().astype(str).unique().tolist())\n",
    "\n",
    "    def _build_widgets(self):\n",
    "        w = self.w\n",
    "\n",
    "        types   = self._uniq(self.media[\"type\"]) if \"type\" in self.media else [\"audio\"]\n",
    "        devices = self._uniq(self.DATA[\"device_display\"]) if \"device_display\" in self.DATA else [\"unknown\"]\n",
    "        places  = self._uniq(self.DATA[\"location\"]) if \"location\" in self.DATA else []\n",
    "\n",
    "        def _rows(n): return max(3, min(10, int(n)))\n",
    "\n",
    "        w[\"title_html\"] = W.HTML(\"<div style='font-size:22px;font-weight:800;color:#1f4b9a'>Sound Atlas Dataset Dashboard</div>\")\n",
    "        w[\"status1\"]    = W.HTML(\"\")\n",
    "        w[\"status3\"]    = W.HTML(\"\")\n",
    "\n",
    "        w[\"search\"] = W.Text(placeholder=\"Search: name / location / device…\", layout=W.Layout(width=\"100%\"))\n",
    "        w[\"place\"]  = W.SelectMultiple(options=places,  value=(),             description=\"Location\",\n",
    "                                       rows=_rows(len(places)), layout=W.Layout(width=\"100%\"))\n",
    "        w[\"device\"] = W.SelectMultiple(options=devices, value=tuple(devices), description=\"Device\",\n",
    "                                       rows=_rows(len(devices)), layout=W.Layout(width=\"100%\"))\n",
    "        w[\"type\"]   = W.SelectMultiple(options=types,   value=tuple(types),   description=\"Type\",\n",
    "                                       rows=_rows(len(types)), layout=W.Layout(width=\"100%\"))\n",
    "\n",
    "        w[\"only_samples\"] = W.Checkbox(value=False, description=\"Only items with sample clip\")\n",
    "\n",
    "        all_dates = self.DATA[\"date_only\"].dropna() if \"date_only\" in self.DATA else pd.Series([], dtype=\"object\")\n",
    "        dmin = all_dates.min() if not all_dates.empty else None\n",
    "        dmax = all_dates.max() if not all_dates.empty else None\n",
    "\n",
    "        # Use calendar as date picker\n",
    "        self.date_watch_widgets = []\n",
    "        try:\n",
    "            import ipyvuetify as v\n",
    "            init_model = [dmin.isoformat(), dmax.isoformat()] if (dmin and dmax) else []\n",
    "            w[\"datepicker\"] = v.DatePicker(range=True, v_model=init_model, full_width=True, elevation=1,\n",
    "                                           show_current=True, no_title=True)\n",
    "            self.date_ui = w[\"datepicker\"]\n",
    "            def _get_date_range():\n",
    "                vm = w[\"datepicker\"].v_model or []\n",
    "                from datetime import date\n",
    "                s = date.fromisoformat(vm[0]) if len(vm)>=1 and vm[0] else None\n",
    "                e = date.fromisoformat(vm[1]) if len(vm)>=2 and vm[1] else None\n",
    "                return s, e\n",
    "            self.get_date_range = _get_date_range\n",
    "            self.date_watch_widgets = [w[\"datepicker\"]]\n",
    "        except Exception:\n",
    "            try:\n",
    "                from ipydatetime import DateRangePicker\n",
    "                w[\"date_range\"] = DateRangePicker(start=dmin, end=dmax, layout=W.Layout(width=\"100%\"))\n",
    "                self.date_ui = w[\"date_range\"]\n",
    "                def _get_date_range():\n",
    "                    return (w[\"date_range\"].start, w[\"date_range\"].end)\n",
    "                self.get_date_range = _get_date_range\n",
    "                self.date_watch_widgets = [w[\"date_range\"]]\n",
    "            except Exception:\n",
    "                w[\"date_start\"] = W.DatePicker(description=\"Start\", value=dmin, layout=W.Layout(width=\"49%\"))\n",
    "                w[\"date_end\"]   = W.DatePicker(description=\"End\",   value=dmax, layout=W.Layout(width=\"49%\"))\n",
    "                self.date_ui = W.HBox([w[\"date_start\"], w[\"date_end\"]], layout=W.Layout(width=\"100%\", gap=\"8px\"))\n",
    "                def _get_date_range():\n",
    "                    return (w[\"date_start\"].value, w[\"date_end\"].value)\n",
    "                self.get_date_range = _get_date_range\n",
    "                self.date_watch_widgets = [w[\"date_start\"], w[\"date_end\"]]\n",
    "\n",
    "        w[\"cluster\"] = W.ToggleButtons(options=[(\"Cluster pins\",\"Cluster\"), (\"Single markers\",\"Markers\")],\n",
    "                                       value=\"Cluster\", description=\"Display\")\n",
    "        w[\"colorby\"] = W.ToggleButtons(options=[\"device\",\"type\"], value=\"device\", description=\"Color by\")\n",
    "        w[\"iconby\"]  = W.ToggleButtons(options=[(\"Type icons\",\"type\"), (\"Plain dot\",\"dot\")],\n",
    "                                       value=\"type\", description=\"Icon style\")\n",
    "        w[\"popup\"]   = W.ToggleButtons(options=[\"compact\",\"detailed\"], value=\"compact\", description=\"Popup\")\n",
    "\n",
    "        w[\"export_c\"] = W.Button(description=\"Export CSV\")\n",
    "        w[\"export_g\"] = W.Button(description=\"Export GeoJSON\")\n",
    "        w[\"reset\"]    = W.Button(description=\"Reset filters\", button_style=\"warning\")\n",
    "\n",
    "    def _init_map(self):\n",
    "        self.m = leafmap.Map(center=(23.565,119.579), zoom=11, basemap=\"OpenStreetMap\")\n",
    "        self.m.layout = W.Layout(width=\"66%\", height=\"85vh\")\n",
    "        for ctrl in list(self.m.controls): self.m.remove_control(ctrl)\n",
    "        self.m.add_control(ZoomControl(position=\"topleft\"))\n",
    "        self.m.add(FullScreenControl())\n",
    "        self.m.close_popup_on_click = False\n",
    "\n",
    "    def _layout_panel(self):\n",
    "        w = self.w\n",
    "\n",
    "        def group_box(title, *kids):\n",
    "            return W.VBox(\n",
    "                [W.HTML(f\"<div style='font-weight:700;color:#1f4b9a;margin-bottom:6px'>{title}</div>\"), *kids],\n",
    "                layout=W.Layout(width=\"100%\", padding=\"10px\", margin=\"8px 0\",\n",
    "                                border=\"1px solid #d0d7de\", border_radius=\"8px\", background_color=\"white\")\n",
    "            )\n",
    "\n",
    "        filters_group = group_box(\n",
    "            \"Filters\",\n",
    "            w[\"search\"], w[\"place\"], w[\"device\"], w[\"type\"], w[\"only_samples\"],\n",
    "            W.HTML(\"<b>Date range</b>\"), self.date_ui,\n",
    "            W.HBox([w[\"reset\"]], layout=W.Layout(justify_content=\"flex-end\", width=\"100%\")),\n",
    "        )\n",
    "\n",
    "        display_group = group_box(\n",
    "            \"Display\",\n",
    "            W.HBox([w[\"cluster\"], w[\"colorby\"], w[\"iconby\"], w[\"popup\"]], layout=W.Layout(gap=\"6px\", flex_wrap=\"wrap\"))\n",
    "        )\n",
    "\n",
    "        export_group  = group_box(\"Export\", W.HBox([w[\"export_c\"], w[\"export_g\"]], layout=W.Layout(gap=\"8px\")))\n",
    "\n",
    "        header = W.VBox([w[\"title_html\"], W.HTML(\"\"), W.HTML(\"\")], layout=W.Layout(margin=\"0 0 8px 0\"))\n",
    "        self.w_status1, self.w_status3 = header.children[1], header.children[2]\n",
    "\n",
    "        panel = W.VBox([header, filters_group, display_group, export_group],\n",
    "                       layout=W.Layout(width=\"34%\", padding=\"8px\", border=\"1px solid #ddd\",\n",
    "                                       margin=\"0 0 0 8px\", overflow_y=\"visible\"))\n",
    "\n",
    "        display(W.HBox([self.m, panel], layout=W.Layout(width=\"100%\")))\n",
    "\n",
    "    # =================================== Filtering / Helpers ====================================\n",
    "    def _text_hit(self, row, q):\n",
    "        if not q: return True\n",
    "        q = q.lower().strip()\n",
    "        for c in [\"display_name\",\"file_name\",\"name\",\"location\",\"device\",\"device_meta\",\"device_display\"]:\n",
    "            v = row.get(c)\n",
    "            if isinstance(v, str) and q in v.lower():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def apply_filters(self):\n",
    "        f = self.DATA.copy()\n",
    "        if self.w[\"place\"].value and \"location\" in f.columns:\n",
    "            f = f[f[\"location\"].astype(str).isin(list(self.w[\"place\"].value))]\n",
    "        if self.w[\"device\"].value and \"device_display\" in f.columns:\n",
    "            f = f[f[\"device_display\"].astype(str).isin(list(self.w[\"device\"].value))]\n",
    "        if self.w[\"type\"].value and \"type\" in f.columns:\n",
    "            f = f[f[\"type\"].astype(str).isin(list(self.w[\"type\"].value))]\n",
    "\n",
    "        if self.w[\"only_samples\"].value and \"has_media_local\" in f.columns:\n",
    "            f = f[f[\"has_media_local\"]]\n",
    "\n",
    "        s, e = self.get_date_range()\n",
    "        if s and not e: e = s\n",
    "        if e and not s: s = e\n",
    "        if s and e and \"date_only\" in f.columns:\n",
    "            dser = f[\"date_only\"]\n",
    "            f = f[(dser >= s) & (dser <= e)]\n",
    "\n",
    "        if self.w[\"search\"].value.strip():\n",
    "            f = f[f.apply(lambda r: self._text_hit(r, self.w[\"search\"].value), axis=1)]\n",
    "\n",
    "        if \"lat\" in f.columns and \"lon\" in f.columns:\n",
    "            f = f.dropna(subset=[\"lat\",\"lon\"])\n",
    "        else:\n",
    "            f = f.iloc[0:0]\n",
    "        return f\n",
    "\n",
    "    def mk_color_map(self, values):\n",
    "        cm, i = {}, 0\n",
    "        for v in values:\n",
    "            if v not in cm:\n",
    "                cm[v] = self.PALETTE[i % len(self.PALETTE)]; i += 1\n",
    "        return cm\n",
    "\n",
    "    # ==================================== Popup Rendering =======================================\n",
    "    @staticmethod\n",
    "    def _section_header(title: str, count: int):\n",
    "        return (\n",
    "            f\"<div style='margin:10px 0 6px 0;padding:6px 8px;background:#f6f8fa;\"\n",
    "            f\"border:1px solid #d0d7de;border-radius:6px;font-weight:700'>\"\n",
    "            f\"{title} <span style='font-weight:500;color:#555'>( {count} )</span>\"\n",
    "            f\"</div>\"\n",
    "        )\n",
    "\n",
    "    def popup_group_html(self, group_df: pd.DataFrame, mode=\"compact\"):\n",
    "        g = group_df.copy()\n",
    "        first = g.iloc[0]\n",
    "        date_header = str(first.get(\"date_only\") or \"\")\n",
    "        location_header = first.get(\"location\") or \"\"\n",
    "\n",
    "        def _time_key(row):\n",
    "            v = row.get(\"date_norm\")\n",
    "            ts = pd.to_datetime(v, errors=\"coerce\")\n",
    "            return (ts.hour if pd.notna(ts) else 99, ts.minute if pd.notna(ts) else 99, ts.second if pd.notna(ts) else 99)\n",
    "\n",
    "        sec_order = [(\"audio\",\"Audio\"),(\"video\",\"Video\"),(\"image\",\"Image\")]\n",
    "        sections_html, total_items = [], 0\n",
    "\n",
    "        for tkey, ttitle in sec_order:\n",
    "            sec = g[g[\"type\"].astype(str).str.lower().eq(tkey)].copy()\n",
    "            if sec.empty: continue\n",
    "            sec[\"_tkey\"] = sec.apply(_time_key, axis=1)\n",
    "            sec = sec.sort_values(by=[\"_tkey\"]).drop(columns=[\"_tkey\"])\n",
    "            total_items += len(sec)\n",
    "\n",
    "            html = [self._section_header(ttitle, len(sec))]\n",
    "            for i, (_, row) in enumerate(sec.iterrows(), start=1):\n",
    "                url  = row.get(\"url\") or self._local_media_url(row)\n",
    "                time_only = self._format_time_only(row)\n",
    "                duration  = str(row.get(\"duration\") or \"\").strip()\n",
    "                fname     = row.get(\"file_name\") or row.get(\"filename\") or \"\"\n",
    "\n",
    "                mime = self.infer_mime(url)\n",
    "                if mime.startswith(\"image/\"):\n",
    "                    media = f'<img src=\"{url}\" style=\"max-width:300px;border:1px solid #ddd;border-radius:4px;\">'\n",
    "                elif mime.startswith(\"video/\"):\n",
    "                    media = f'<video controls preload=\"none\" style=\"width:300px;\" playsinline><source src=\"{url}\" type=\"{mime}\"></video>'\n",
    "                else:\n",
    "                    media = f'<audio controls preload=\"none\" style=\"width:300px;\"><source src=\"{url}\" type=\"{mime}\"></audio>'\n",
    "\n",
    "                missing = \"\" if url else \"<div style='color:#b00020;margin-top:4px'>Media not found in ./data</div>\"\n",
    "\n",
    "                extra = \"\"\n",
    "                if mode == \"detailed\":\n",
    "                    exclude = {\n",
    "                        \"lat\",\"lon\",\"url\",\"file_name\",\"filename\",\"date_only\",\"date_norm\",\n",
    "                        \"location\",\"duration\",\"type\",\"display_name\",\"device\",\"device_meta\",\"device_display\",\n",
    "                        \"datetime\",\"time\"\n",
    "                    }\n",
    "                    kv = []\n",
    "                    for k, v in row.items():\n",
    "                        if k in exclude: continue\n",
    "                        if isinstance(v, float) and np.isnan(v): continue\n",
    "                        if v is None or (isinstance(v, str) and v.strip()==\"\"): continue\n",
    "                        kv.append(f\"{k}: {v}\")\n",
    "                    if kv: extra = \"<div style='color:#666;margin-top:4px'>\" + \"<br>\".join(kv) + \"</div>\"\n",
    "\n",
    "                html.append(\n",
    "                    f\"\"\"\n",
    "                    <div style=\"margin:8px 0 14px 0;padding:6px 8px;border-left:3px solid #eaecef;\">\n",
    "                      <div style=\"font-weight:600;margin:0 0 6px 0\">item #{i}</div>\n",
    "                      <div>time: <b>{time_only or '—'}</b></div>\n",
    "                      <div>duration: <b>{duration or '—'}</b></div>\n",
    "                      <div>file name: <code>{fname or '—'}</code></div>\n",
    "                      {media}\n",
    "                      {missing}\n",
    "                      {extra}\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "                )\n",
    "            sections_html.append(\"\".join(html))\n",
    "\n",
    "        header_html = f\"\"\"\n",
    "            <div style=\"margin-bottom:8px\">\n",
    "              <div><b>date:</b> {date_header or '—'}</div>\n",
    "              <div><b>location:</b> {location_header or '—'}</div>\n",
    "              <div style=\"margin:6px 0 10px 0;\"><b>items on this date:</b> {total_items}</div>\n",
    "            </div>\n",
    "        \"\"\"\n",
    "        body = \"\".join(sections_html)\n",
    "        return f\"<div style='max-height:60vh; overflow:auto; padding-right:6px'>{header_html}{body}</div>\"\n",
    "\n",
    "    # ===================================== Auto-fit helpers =====================================\n",
    "    def _fit_bounds_from_df(self, df, *, min_zoom=11, single_zoom=16, pad_ratio=0.06):\n",
    "        if df is None or df.empty or \"lat\" not in df or \"lon\" not in df:\n",
    "            self.m.center = (23.565, 119.579); self.m.zoom = min_zoom\n",
    "            return\n",
    "\n",
    "        s = df.copy()\n",
    "        s[\"lat\"] = pd.to_numeric(s[\"lat\"], errors=\"coerce\")\n",
    "        s[\"lon\"] = pd.to_numeric(s[\"lon\"], errors=\"coerce\")\n",
    "        s = s.dropna(subset=[\"lat\",\"lon\"])\n",
    "        if s.empty:\n",
    "            self.m.center = (23.565, 119.579); self.m.zoom = min_zoom\n",
    "            return\n",
    "\n",
    "        uniq_locs = s[[\"lat\",\"lon\"]].drop_duplicates()\n",
    "        if len(uniq_locs) == 1:\n",
    "            self.m.center = (float(uniq_locs[\"lat\"].iloc[0]), float(uniq_locs[\"lon\"].iloc[0]))\n",
    "            self.m.zoom = single_zoom\n",
    "            return\n",
    "\n",
    "        lat_min, lat_max = float(s[\"lat\"].min()), float(s[\"lat\"].max())\n",
    "        lon_min, lon_max = float(s[\"lon\"].min()), float(s[\"lon\"].max())\n",
    "        if not all(map(np.isfinite, [lat_min, lat_max, lon_min, lon_max])):\n",
    "            self.m.center = (23.565, 119.579); self.m.zoom = min_zoom\n",
    "            return\n",
    "\n",
    "        dlat = (lat_max - lat_min)\n",
    "        dlon = (lon_max - lon_min)\n",
    "        pad_lat = max(dlat * pad_ratio, 1e-5)\n",
    "        pad_lon = max(dlon * pad_ratio, 1e-5)\n",
    "        self.m.fit_bounds([[lat_min - pad_lat, lon_min - pad_lon],\n",
    "                           [lat_max + pad_lat, lon_max + pad_lon]])\n",
    "\n",
    "    def _filter_signature(self):\n",
    "        s, e = self.get_date_range()\n",
    "        return (\n",
    "            tuple(sorted(self.w[\"place\"].value)) if hasattr(self.w[\"place\"], \"value\") else (),\n",
    "            tuple(sorted(self.w[\"device\"].value)) if hasattr(self.w[\"device\"], \"value\") else (),\n",
    "            tuple(sorted(self.w[\"type\"].value)) if hasattr(self.w[\"type\"], \"value\") else (),\n",
    "            bool(self.w[\"only_samples\"].value) if hasattr(self.w[\"only_samples\"], \"value\") else False,\n",
    "            (str(s), str(e)),\n",
    "            (self.w[\"search\"].value or \"\").strip().lower(),\n",
    "            self.w[\"cluster\"].value, self.w[\"colorby\"].value, self.w[\"iconby\"].value, self.w[\"popup\"].value\n",
    "        )\n",
    "\n",
    "    def _compute_extent_tuple(self, df):\n",
    "        if df is None or df.empty or \"lat\" not in df or \"lon\" not in df:\n",
    "            return (\"empty\",)\n",
    "        s = df.copy()\n",
    "        s[\"lat\"] = pd.to_numeric(s[\"lat\"], errors=\"coerce\")\n",
    "        s[\"lon\"] = pd.to_numeric(s[\"lon\"], errors=\"coerce\")\n",
    "        s = s.dropna(subset=[\"lat\",\"lon\"])\n",
    "        if s.empty:\n",
    "            return (\"empty\",)\n",
    "        lat_min, lat_max = float(s[\"lat\"].min()), float(s[\"lat\"].max())\n",
    "        lon_min, lon_max = float(s[\"lon\"].min()), float(s[\"lon\"].max())\n",
    "        group_count = int(s.groupby([\"lat\",\"lon\",\"date_only\"], dropna=False).size().shape[0])\n",
    "        uniq_loc_count = int(s[[\"lat\",\"lon\"]].dropna().drop_duplicates().shape[0])\n",
    "        return (round(lat_min, 6), round(lat_max, 6), round(lon_min, 6), round(lon_max, 6), group_count, uniq_loc_count)\n",
    "\n",
    "    # ======================================= Render =============================================\n",
    "    def _clear_dynamic(self):\n",
    "        for k, ctrl in list(self.DYNAMIC.items()):\n",
    "            if ctrl is not None:\n",
    "                try: self.m.remove_control(ctrl)\n",
    "                except Exception: pass\n",
    "                self.DYNAMIC[k] = None\n",
    "\n",
    "    def _clear_data_layers(self):\n",
    "        for lyr in self.DATA_LAYERS:\n",
    "            try: self.m.remove_layer(lyr)\n",
    "            except Exception: pass\n",
    "        self.DATA_LAYERS = []\n",
    "\n",
    "    def render(self, *_):\n",
    "        f = self.apply_filters()\n",
    "        n = len(f)\n",
    "\n",
    "        # Header texts\n",
    "        self.w_status1.value = f\"<div style='font-size:14px;color:#333'>Showing <b>{n}</b> items</div>\"\n",
    "        s, e = self.get_date_range()\n",
    "        if s or e:\n",
    "            self.w_status3.value = (\n",
    "                f\"<div style='font-size:13px;color:#666'>Date: {s if s else e} — {e if e else s}</div>\"\n",
    "                if (s and e) else f\"<div style='font-size:13px;color:#666'>Date: {s or e}</div>\"\n",
    "            )\n",
    "        else:\n",
    "            self.w_status3.value = f\"<div style='font-size:13px;color:#666'>Date: all</div>\"\n",
    "\n",
    "        # Reset layers & overlays (leave basemap intact)\n",
    "        self._clear_data_layers()\n",
    "        self._clear_dynamic()\n",
    "\n",
    "        # Auto-fit decision\n",
    "        new_sig = self._filter_signature()\n",
    "        curr_type_sel = tuple(sorted(self.w[\"type\"].value)) if hasattr(self.w[\"type\"], \"value\") else ()\n",
    "        type_changed = (curr_type_sel != (self.LAST_TYPE_SEL or ()))\n",
    "        new_extent = self._compute_extent_tuple(f)\n",
    "        extent_changed = (new_extent != self.LAST_EXTENT)\n",
    "        should_autofit = self.FIRST_RENDER or (new_sig != self.LAST_FILTER_SIG) or type_changed or extent_changed\n",
    "\n",
    "        if n > 0:\n",
    "            # Color mapping by current choice (device/type)\n",
    "            color_key = \"device_display\" if self.w[\"colorby\"].value == \"device\" else \"type\"\n",
    "            uniq = sorted([str(x) for x in f[color_key].fillna(\"unknown\").astype(str).unique()])\n",
    "            color_map = self.mk_color_map(uniq)\n",
    "\n",
    "            # Group rows by (lat, lon, date_only), one location marker per group\n",
    "            f[\"lat\"] = f[\"lat\"].astype(float)\n",
    "            f[\"lon\"] = f[\"lon\"].astype(float)\n",
    "            grouped_iter = f.groupby([\"lat\", \"lon\", \"date_only\"], dropna=False)\n",
    "\n",
    "            markers = []\n",
    "            for (_, _, _), g in grouped_iter:\n",
    "                first = g.iloc[0]\n",
    "                keyval = str(first.get(color_key, \"unknown\"))\n",
    "                color = color_map.get(keyval, \"gray\")\n",
    "                icon = AwesomeIcon(\n",
    "                    name=(\n",
    "                        \"music\" if str(first.get(\"type\", \"\")).lower() == \"audio\"\n",
    "                        else \"video-camera\" if str(first.get(\"type\", \"\")).lower() == \"video\"\n",
    "                        else \"image\"\n",
    "                    ) if self.w[\"iconby\"].value == \"type\" else \"circle\",\n",
    "                    marker_color=color,\n",
    "                    icon_color=\"white\",\n",
    "                )\n",
    "                loc = (float(g[\"lat\"].iloc[0]), float(g[\"lon\"].iloc[0]))\n",
    "                mk = Marker(location=loc, title=self._format_time_title(first), icon=icon, draggable=False)\n",
    "\n",
    "                pop = Popup(\n",
    "                    child=W.HTML(value=self.popup_group_html(g, mode=self.w[\"popup\"].value)),\n",
    "                    max_width=400, min_width=340, auto_close=False, close_button=True, keep_in_view=True,\n",
    "                )\n",
    "                mk.popup = pop\n",
    "\n",
    "                def _bind_open_popup(marker, group_df):\n",
    "                    def _cb(**kwargs):\n",
    "                        marker.popup.child.value = self.popup_group_html(group_df, mode=self.w[\"popup\"].value)\n",
    "                        marker.open_popup()\n",
    "                    return _cb\n",
    "                mk.on_click(_bind_open_popup(mk, g.copy()))\n",
    "\n",
    "                markers.append(mk)\n",
    "\n",
    "            if self.w[\"cluster\"].value == \"Cluster\":\n",
    "                cluster_layer = MarkerCluster(markers=markers)\n",
    "                self.m.add_layer(cluster_layer); self.DATA_LAYERS.append(cluster_layer)\n",
    "            else:\n",
    "                for mk in markers:\n",
    "                    self.m.add_layer(mk); self.DATA_LAYERS.append(mk)\n",
    "\n",
    "            # Legend overlay (counts by chosen color_key)\n",
    "            counts = f[color_key].fillna(\"unknown\").astype(str).value_counts().to_dict()\n",
    "            legend_items = \"\".join(\n",
    "                f'<div style=\"margin:2px 0;\"><span style=\"display:inline-block;width:12px;height:20px;'\n",
    "                f'background:{col};margin-right:6px;border:1px solid #333;\"></span>{lab} ({counts.get(lab,0)})</div>'\n",
    "                for lab, col in color_map.items()\n",
    "            )\n",
    "            legend_html = W.HTML(value=f\"\"\"\n",
    "            <div style=\"background: white; padding: 8px 10px; border: 1px solid #bbb; border-radius: 6px;\n",
    "                        box-shadow: 0 1px 3px rgba(0,0,0,.2); font-size: 14px; max-height: 40vh; overflow:auto;\">\n",
    "              <b>Color by: {'device' if self.w[\"colorby\"].value=='device' else 'type'}</b><br>\n",
    "              {legend_items}\n",
    "            </div>\n",
    "            \"\"\")\n",
    "            ctrl = WidgetControl(widget=legend_html, position=\"bottomleft\")\n",
    "            self.m.add_control(ctrl); self.DYNAMIC[\"legend\"] = ctrl\n",
    "\n",
    "            if should_autofit:\n",
    "                try:\n",
    "                    self._fit_bounds_from_df(f, min_zoom=11, single_zoom=16, pad_ratio=0.06)\n",
    "                except Exception:\n",
    "                    self.m.center = (23.565, 119.579); self.m.zoom = 11\n",
    "\n",
    "        else:\n",
    "            notice = W.HTML(value=\"\"\"\n",
    "            <div style=\"background: rgba(255,255,255,.9); padding: 8px 10px; border: 1px solid #bbb; border-radius: 6px;\n",
    "                        box-shadow: 0 1px 3px rgba(0,0,0,.2); font-size: 13px;\">\n",
    "              <b>No matching items</b> — adjust filters to see markers.\n",
    "            </div>\n",
    "            \"\"\")\n",
    "            ctrl = WidgetControl(widget=notice, position=\"topleft\")\n",
    "            self.m.add_control(ctrl); self.DYNAMIC[\"notice\"] = ctrl\n",
    "\n",
    "            if should_autofit:\n",
    "                self.m.center = (23.565, 119.579); self.m.zoom = 11\n",
    "\n",
    "        # Update trackers\n",
    "        self.FIRST_RENDER  = False\n",
    "        self.LAST_FILTER_SIG = new_sig\n",
    "        self.LAST_TYPE_SEL   = curr_type_sel\n",
    "        self.LAST_EXTENT     = new_extent\n",
    "\n",
    "    # =================================== Actions / Events =======================================\n",
    "    def on_reset(self, _=None):\n",
    "        w = self.w\n",
    "        w[\"search\"].value = \"\"\n",
    "        w[\"place\"].options = self._uniq(self.DATA[\"location\"]) if \"location\" in self.DATA else []\n",
    "        w[\"place\"].value  = ()\n",
    "        w[\"device\"].value = tuple(self._uniq(self.DATA[\"device_display\"]) or [\"unknown\"])\n",
    "        w[\"type\"].options = self._uniq(self.media[\"type\"]) if \"type\" in self.media else [\"audio\"]\n",
    "        w[\"type\"].value   = tuple(w[\"type\"].options)\n",
    "\n",
    "        all_dates = self.DATA[\"date_only\"].dropna() if \"date_only\" in self.DATA else pd.Series([], dtype=\"object\")\n",
    "        dmin = all_dates.min() if not all_dates.empty else None\n",
    "        dmax = all_dates.max() if not all_dates.empty else None\n",
    "\n",
    "        if \"datepicker\" in w:\n",
    "            w[\"datepicker\"].v_model = [dmin.isoformat(), dmax.isoformat()] if (dmin and dmax) else []\n",
    "        elif \"date_range\" in w:\n",
    "            w[\"date_range\"].start, w[\"date_range\"].end = dmin, dmax\n",
    "        else:\n",
    "            if \"date_start\" in w: w[\"date_start\"].value = dmin\n",
    "            if \"date_end\"   in w: w[\"date_end\"].value   = dmax\n",
    "\n",
    "        w[\"only_samples\"].value = False\n",
    "        w[\"cluster\"].value=\"Cluster\"; w[\"colorby\"].value=\"device\"; w[\"iconby\"].value=\"type\"; w[\"popup\"].value=\"compact\"\n",
    "        self.render()\n",
    "\n",
    "    def export_csv(self, _=None):\n",
    "        f = self.apply_filters(); path = \"filtered_export.csv\"; f.to_csv(path, index=False)\n",
    "        self.w_status1.value = f\"<div style='font-size:14px;color:#333'>Saved CSV • {len(f)} rows → <code>{path}</code></div>\"\n",
    "\n",
    "    def export_geojson(self, _=None):\n",
    "        f = self.apply_filters(); path = \"filtered_export.geojson\"\n",
    "        def feat(row):\n",
    "            return {\"type\":\"Feature\",\n",
    "                    \"geometry\":{\"type\":\"Point\",\"coordinates\":[float(row[\"lon\"]), float(row[\"lat\"])]},\n",
    "                    \"properties\": {\n",
    "                        k:(None if (isinstance(v,float) and np.isnan(v)) else v)\n",
    "                        for k,v in row.drop(labels=[\"lat\",\"lon\"]).items()\n",
    "                    }}\n",
    "        gj = {\"type\":\"FeatureCollection\",\"features\":[feat(r) for _, r in f.iterrows()]}\n",
    "        with open(path,\"w\",encoding=\"utf-8\") as fp: json.dump(gj, fp, ensure_ascii=False)\n",
    "        self.w_status1.value = f\"<div style='font-size:14px;color:#333'>Saved GeoJSON • {len(f)} features → <code>{path}</code></div>\"\n",
    "\n",
    "    def _rerender(self, *_): self.render()\n",
    "\n",
    "    def _wire_events(self):\n",
    "        w = self.w\n",
    "        w[\"reset\"].on_click(self.on_reset)\n",
    "        w[\"export_c\"].on_click(self.export_csv)\n",
    "        w[\"export_g\"].on_click(self.export_geojson)\n",
    "\n",
    "        watch = [w[\"search\"], w[\"place\"], w[\"device\"], w[\"type\"], w[\"only_samples\"],\n",
    "                 w[\"cluster\"], w[\"colorby\"], w[\"iconby\"], w[\"popup\"]] + self.date_watch_widgets\n",
    "        for ctrl in watch:\n",
    "            if hasattr(ctrl, \"observe\"):\n",
    "                if hasattr(ctrl, \"v_model\"): ctrl.observe(self._rerender, names=\"v_model\")\n",
    "                else:                        ctrl.observe(self._rerender, names=\"value\")\n",
    "\n",
    "# ---- Run (instantiate) ------------------------------------------------------------------------\n",
    "_DASHBOARD_INSTANCE = DataRainbowDashboard()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d88d81-569f-4b99-8e25-2300ca190d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expose the ipyleaflet/leafmap widget for export & Live Code\n",
    "m = _DASHBOARD_INSTANCE.m\n",
    "# Optional: show just the map widget too\n",
    "# m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df4ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Static export (runs only in CI when EXPORT_STATIC=1)\n",
    "import os\n",
    "from ipywidgets.embed import embed_minimal_html\n",
    "\n",
    "if os.environ.get(\"EXPORT_STATIC\") == \"1\":\n",
    "    os.makedirs(\"docs/_static\", exist_ok=True)\n",
    "    embed_minimal_html(\n",
    "        \"docs/_static/dashboard_static.html\",\n",
    "        views=[m],\n",
    "        title=\"Data Rainbow — Static Dashboard\"\n",
    "    )\n",
    "    print(\"Exported docs/_static/dashboard_static.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
